{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #time.sleep()쓰기 위함 \n",
    "from selenium import webdriver  #webdriver 쓰기 위함 \n",
    "from selenium.webdriver.chrome.options import Options  #이 코드라인이 없으면, 에러가 나온다. \n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "# 크롬 옵션 headless 모드로 실행\n",
    "options = Options()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--window-size=1080,1080')\n",
    "\n",
    "\n",
    "# 크롬 드라이버 경로 지정\n",
    "driver_path = 'chromedriver'\n",
    "\n",
    "# 크롬 드라이버 객체 생성\n",
    "browser = webdriver.Chrome(executable_path=driver_path, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5'\n",
    "browser.get(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 논문 링크 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230851', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230843', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230845', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230844', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288340', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231160', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231378', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288024', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231192', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230847', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11337935', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230365', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11342633', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231818', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11225163', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11229021', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228571', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228572', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219382', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219168']\n"
     ]
    }
   ],
   "source": [
    "#논문 링크만 쭉 가져오는 코드 \n",
    "#link = browser.find_element(By.CLASS_NAME,'thesis_link').get_attribute('href')\n",
    "datas = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "detail_url_list = []\n",
    "for i in datas:\n",
    "    detail_url = i.get_attribute('href')\n",
    "    detail_url_list.append(detail_url)\n",
    "\n",
    "print(detail_url_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in detail_url_list:\n",
    "    browser.get(link)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제목 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제목, 초록*키워드 가져와 보시고, \n",
    "# 다하신분들은 => 3페이지까지도 해보시고요. \n",
    "datas = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "title_list = []\n",
    "\n",
    "for i in datas:\n",
    "    title = i.find_element(By.TAG_NAME,'h2').text\n",
    "    # print(title)\n",
    "    title_list.append(title)\n",
    "\n",
    "title_list\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 초록이 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "\n",
    "\n",
    "content_list = []\n",
    "\n",
    "for i in datas:\n",
    "    try:\n",
    "        content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "        # print( content, '\\n')\n",
    "    except:\n",
    "        print(\"No text value for class='thesis__abstract'\")\n",
    "    content_list.append(content)\n",
    "content_list\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다 합쳐서 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목: 인공지능 융합교육을 위한 초중등학교 연계형 인공지능 교육 내용체계 개발\n",
      "초록이: 본 연구의 목적은 체계적인 인공지능 융합교육을 지원하기 위한 초중등학교 연계형 인공지능 교육 내용체계를 개발하는 것이다. 이를 위해, 국내·외 인공지능 교육 관련 내용 체계 동향을 분석하여 초중등 학교급별 교육영역 및 내용요소를 추출하였다. 내용체계 초안에 대해 11명의 전문가에게 2차에 걸친 델파이 및 FGI를 통해 수정 보완하여 타당도를 검증하였다. 연구 결과, 교육 내용체계는 초등학교 1~4학년과 5~6학년, 중학교, 고등학교의 4단계로 제시되었다. 또한, 이 내용체계는 'AI 이해', 'AI 윤리', 'AI 활용', 'AI 융합'의 4개 대영역과 총 9개의 하위영역으로 구성되었으며, 총 95개의 내용요소를 제시함으로써 모든 영역에서 학교급별로 연계될 수 있도록 개발하였다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230851 \n",
      "\n",
      "제목: 직업계 고등학교 학생의 인공지능 리터러시 프로그램 개발 및 적용\n",
      "초록이: 산업현장에 인공지능 기술이 도입되고 이 기술을 활용해야 하는 직업계 고등학교 학생에게 인공지능 리터러시를 길러줄 필요가 있다. 이에 본 연구에서는 인공지능 기초 교과의 성취기준과 학생의 특성을 반영하여 10차시의 리터러시 프로그램을 개발하고 공업계열의 2학년 학생을 대상으로 프로그램을 적용하였다. 연구 결과 학생들의 에 대한 태도와 자기효능감은 t-검정에서 유의미한 차이가 있었고 효과크기 분석에서 중간 크기 이상의 결과가 나왔다. 그리고 학습자 반응 분석에서 의 이해도는 향상되었으며 대부분의 학생이 프로그램에 만족하는 것으로 나타났다. 이 연구는 직업계 고등학교의 계열별 특성에 적합한 리터러시 교육의 후속 연구와 학교 현장에서 교육이 안정적으로 정착하는 데에 이바지하고자 한다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230843 \n",
      "\n",
      "제목: 책임윤리 기반의 초등학생을 위한 인공지능 윤리교육 프로그램 개발 및 적용\n",
      "초록이: 본 연구에서는 한스 요나스의 책임윤리론을 기반으로 하여, 초등학생들이 현재 세대 및 미래 세대를 고려한 기술 발전의 관점에서 인공지능을 생각하도록 하는 교육 프로그램을 개발 및 적용하였다. 본 연구의 목적을 달성하기 위해 백워드 설계 모형을 기반으로 6차시의 수업 프로그램을 계획하였으며, 그 내용으로 과 관련된 여러 윤리적 문제들에 대해 생각해보는 과정을 통하여 윤리요소를 접할 수 있게 하였고, 에 대한 도덕적 통제가 필요함을 느낄 수 있도록 하였다. 본 연구의 대상은 윤리와 관련된 공교육 경험이 없는 경상북도 소재 D 초등학교의 5학년 학생 22명이었다. 연구 결과 본 교육 프로그램을 통해 학생들은 의 윤리의 중요성에 대한 이해를 바탕으로 윤리 의식이 향상되었음을 확인하였다. 또한 에 대해 긍정적인 인식을 갖고 안전하고 신뢰할 수 있는 의 발전상에 대한 생각을 할 수 있었음을 확인할 수 있었다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230845 \n",
      "\n",
      "제목: 초등 인공지능 교육에서 '생각에 대한 생각' 교육방법의 적용 연구\n",
      "초록이: 현재 대부분 교육과정은 인공지능의 개념을 취사 전달하고 흥미로운 서비스를 체험하는 것으로 이루어져 있으나, 본질적인 교육목표에 대한 논의는 다소 모호하다. 이러한 관점에서 초기에 어린이를 위한 컴퓨팅 사고력과 교육에 대해 논의한 민스키와 페퍼트는 '생각에 대한 생각(thinking about thinking)'을 교육목표로 강조하며 프로그래밍, 알고리즘, 컴퓨터 등이 그러한 인지적 역량 확장을 위한 효율적인 도구라고 주장한다. 본 연구에서는 '생각에 대한 생각' 관점을 초등 교육에 설계·적용하고, 이것이 아이들의 적 사고에 대한 관찰, 표현, 그리고 개선 역량에 긍정적인 효과가 있는지를 확인하고자 한다. 이를 위해 의 '분류·군집' 모델 중 학습자의 실생활과 밀접한 이미지·소리 인식을 주제로 하여 '생각에 대한 생각'을 위한 언플러그드 활동을 설계 및 수업 실험을 진행하였다. 주제별 활동지와 개별 인터뷰 내용의 분석 결과, 주제가 진행될수록 학습자는 문제 해결을 위한 자신의 적 행위·판단을 n차원적으로 분석하였으며 정확도 높은 알고리즘을 위해 다양한 특징(feature)을 발견하였다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230844 \n",
      "\n",
      "제목: 인공지능(AI)의 젠더화된 목소리와 주체화 방식에 대한 사례연구 : 푸코의 장치와 주체화 사유를 중심으로\n",
      "초록이: 본 연구는 푸코의 장치와 주체화 사유를 바탕으로 인공지능(AI)의 젠더화된 목소리에 대한 경험과 주체화 방식을 살펴보았다. 이를 위해 사례연구 절차에 따라 인공지능의 젠더화된 목소리와 관련된 사회문화적 현상을 쟁점화하여 장치의 작동 원리와 주체화 방식을 논의하였고 음성인식 서비스 이용 경험이 있는 20-30대를 연구참여자로 선정해 인터뷰를 진행하였다. 분석 결과, 연구참여자들은 음성인식 서비스를 이용하면서 일상생활의 변화를 경험하였고 그 과정에서 의 젠더화된 목소리를 인식하였다. 의 젠더화된 목소리는 젠더 이데올로기를 유지하고 재생산하는 정치적 도구로서 개인의 사고와 행동에 영향을 주었다. 연구참여자들은 ᐨ데이터의 젠더 편향성, 감시 및 통제로 인해 스스로 예속화하였으나 자기 성찰을 통해 새로운 윤리적 주체를 형성하고자 하는 실천적 가능성을 보여주었다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288340 \n",
      "\n",
      "제목: 유아교사들의 인공지능(AI)을 활용한 교육과정 운영 경험\n",
      "초록이: 본 연구는 인공지능을 활용하여 교육과정을 운영하고 있는 유아교사의 경험의 의미와 필요한 지원을 탐색하고자 하는 목적으로 수행되었다. 본 연구에서는 교육과정 운영에 인공지능을 활용하고 있는 유아교사의 경험을 알아보고자 질적연구방법을 선택하였고, 국․공립유치원 교사 5명을 선정하여 2022년 7월 초부터 9월 중순까지 약 12주 동안 개별면담을 통해 자료를 수집하여 분석, 해석하였다. 연구결과를 살펴보면 첫째, 교사들은 에 대해 두려움을 느끼고 있었지만, 의 활용이 유아에게 긍정적인 영향을 미치는 것을 보며 교사의 인식이 변화하였다. 하지만 의 활용으로 인한 부정적인 영향도 있어 유아를 보호하기 위해 노력하였으며, 유아와 함께 (AI)을 활용하기 위해선 교사의 에 대한 전문성과 역량이 중요하다는 것을 깨달았다. 둘째, 유아교사들은 을 활용한 교육과정 운영 지원을 위해 매체 및 자료 지원, 교육환경구축과 교사연수 및 인력지원을 요구하였다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231160 \n",
      "\n",
      "제목: 전장상황에서 이상징후 분석을 위한 인공지능 모델 개발동향 및 발전방향 연구\n",
      "초록이: 인공지능 기술은 인간을 보조하여 임무수행의 효율성을 단순히 제고시키는 수준을 넘어 인간을 완전히 대체하는 수준으로까지 발전해 나가고 있다. 이러한 인공지능 기술을 군사적 목적으로 활용하기 위한 연구가 크게 주목 받고 있다. 특히 복잡하고 모호한 전장상황을 인간 참모 수준 이상으로 이해하는 기술에 대한 연구가 군사선진국을 중심으로 진행 중이다. 본 논문은 군사적 이상징후를 분석하는 모델 연구동향을 분석하고 발전방향을 제시한다. 이를 위해 현재 전투원 중심으로 수행되고 있는 일반적인 군사정보 분석 절차를 살펴보고, 이 과정에서 발생할 수 있는 다양한 유형의 오류들을 분석한다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231378 \n",
      "\n",
      "제목: 자기 효능감과 위험 지각이 인공지능 추천 시스템의 사용자 경험에 미치는 영향\n",
      "초록이: 상품을 구매하거나, 이동 경로 탐색 등의 일상 속 의사 결정 상황에서 사용자들은 인공지능으로부터 추천을 받고 있지만, 이러한 추천이 언제나 받아들여지는 것은 아니다. 여러 요인이 인공지능 추천 수용에 영향을 줄 수 있는데, 그 중 자기 효능감의 영향을 확인하려는 연구가 최근 활발히 진행되고 있다. 그러나 자기 효능감이 추천 시스템의 사용자 경험에 미치는 영향에 관한 연구는 아직 부족한 실정이다. 따라서 본 연구에서는 자기 효능감이 추천 시스템의 사용자 경험에 어떤 영향을 주는지, 특히 사용성과 추천에 대한 역할 인식을 중점적으로 조사하였다. 더 나아가, 자기 효능감의 영향을 다방면으로 살펴보기 위해 의사 결정에 따른 위험 지각의 정도를 조절해가며 자기 효능감의 영향을 세분화해 살펴보았다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288024 \n",
      "\n",
      "제목: 예비·현직초등교사의 앱인벤터 기반의 인공지능 교육 만족도 분석\n",
      "초록이: 본 논문에서는 예비 초등교사 13명과 현직 초등교사 9명을 대상으로 앱인벤터를 활용한 인공지능 교육을 실시하고 만족도 조사를 통해서 학생들의 배경 변인과의 관련성이 있는지, 그리고 두 그룹의 학생들 사이에 만족도의 차이가 있는지 분석하였다. 연구 결과, 현직 교사는 교육에 대한 흥미도, 난이도, 참여도를 묻는 문항에서 예비 교사보다 모두 만족도가 높았다. 또한, 교육이 의 학습 동기 부여에 도움을 주었는지, 향후 초등학교 수업에 적용해 볼 의향이 있는지를 조사하는 문항에서도 예비 교사보다 긍정적으로 나타났다. 예비교사는 대체적으로 현직 교사에 비해서는 부정적인 측면이 있으나 교육이 의 이해도 향상에 도움이 되었는지, 추가 교육에 참가할 의향이 있는지를 조사하는 문항에서는 현직 교사보다 긍정적으로 나타났다. 두 그룹 학생의 만족도에 의미 있는 차이가 있는지 Mann-Whitney Test로 분석한 결과 통계적인 유의미성은 없었다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231192 \n",
      "\n",
      "제목: 중등 교사를 위한 캡스톤 디자인 수업설계 기반 정보, 수학, 과학 인공지능 융합교육 연수 개발 및 효과 분석\n",
      "초록이: 본 연구의 목적은 미래 교육을 위하여 교사의 인공지능 융합교육 역량을 함양할 수 있는 효과적인 연수 과정을 개발하는 것이다. 따라서 본 연구에서는 융합교육 선행 연구를 토대로 AI와 융합하기 위하여 과학, 수학, 정보를 중심 교과로 추출하였고, 교사교육 방법으로는 캡스톤 디자인을 선정하여 연수 과정을 개발하였다. 효과성 분석을 위해 실험 집단과 통제 집단에게 처치 전과 후에 교수효능감 검사 도구를 투입하였다. 연구 결과, 본 연구에서 개발한 연수 과정을 처치한 실험 집단은 전체 결과 및 모든 하위 영역에서의 통계적으로 유의한 상승을 나타내었다. 따라서 본 연구를 통해 캡스톤 디자인 기반의 정보, 수학, 과학 AI 융합교육 연수 과정은 교사에게 긍정적인 효과가 있음을 확인할 수 있었다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230847 \n",
      "\n",
      "제목: \n",
      "초록이: \n",
      "링크:  \n",
      "\n",
      "제목: 인공지능 기반 실시간 감지가 가능한 산불 경보시스템\n",
      "초록이: \n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230365 \n",
      "\n",
      "제목: \n",
      "초록이: \n",
      "링크:  \n",
      "\n",
      "제목: 인공지능 기법과 차수 저감 모델을 이용한 익형 유동장 예측\n",
      "초록이: \n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231818 \n",
      "\n",
      "제목: 국방분야 인공지능 영상감시체계의 시험평가 발전방안 연구\n",
      "초록이: \n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11225163 \n",
      "\n",
      "제목: \n",
      "초록이: \n",
      "링크:  \n",
      "\n",
      "제목: 인공지능(AI) 단일법 제정 필요성과 행정법학의 과제\n",
      "초록이: 이 글은 인공지능 단일법의 필요성에 대한 법적 근거와 행정에서의 인공지능 활용에 따른 행정법학의 과제에 대해 논하고자 한다. 우리나라는 인공지능에 대한 규범적 대응을 위해 법체계를 정비하는 시점에 있다. 우리 정부의 정책 방향은 기술의 발전과 산업의 진흥을 도모하며 의 역기능을 최소화하기 위한 규범을 정립하는 것이다. 의 편익 최대화와 위험의 최소화의 균형점을 이루기 위해서는 현실에 적합한 규제 프레임워크와 독립적인 거버넌스 구축이 요구된다. 유럽연합은 윤리 규범, 가이드라인과 같은 연성법에서 시작하여 강제력 있는 규제 프레임으로 2021년 4월 법안(AI Act)을 제안한 바 있다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228571 \n",
      "\n",
      "제목: 인공지능 기반 진단방법 특허에 관한 연구\n",
      "초록이: 이와 같은 어려움 속에서 최근 급속도로 발전하고 있는 인공지능 기술은 단시간에 다수의 환자를 정확하게 진단할 수 있는 수단으로서 많은 주목을 받고 있다. 하지만, 특허법상 인공지능 기반 진단방법은 오랫동안 어려운 논의를 이어온 의료방법 및 소프트웨어와 관련된 쟁점을 동시에 내포하고 있어 문제이다. 다만, 의료방법 측면에서 최근 우리 특허 심사기준은 의료방법 중 디지털 수단을 활용한 진단방법에 한해서는 산업상 이용가능성을 인정하는 것으로 개정하였고, 소프트웨어 측면에서도 분야의 기술개발을 촉진하기 위한 각국의 특허 심사기준 정비가 이어지고 있다. 그러나 기대와 달리 전술한 두 가지 쟁점과 관련하여 거절되는 경우가 적지 않다. 이에 본 고에서는 기반 진단방법 특허를 받기 위하여 주의하여야 하는 사항을 검토하여 제시하고자 한다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228572 \n",
      "\n",
      "제목: 이미지 생성 인공지능(AI) 달리(DALL·E)의 활용 사례 연구\n",
      "초록이: 4차 산업의 핵심인 인공지능(AI)기술은 빠른 속도로 진화하면서 최근 시각예술 분야에서도 급격한 발전을 보이고 있다. 본 논문은 멀티모달 인공지능(Multimodal AI)을 활용하여 만든 이미지 생성 AI 달리(DALL·E)를 중심으로 시각예술 분야에서의 활용 사례를 알아보고 그 특징을 살펴보았다. 이론적 고찰로 시각예술 분야에서 (AI)을 활용한 이미지 연구 동향과 최근 꾸준히 성장하는 텍스트 기반 이미지 생성 AI의 현황에 대하여 알아보았다. 이를 바탕으로 이미지 생성 AI 달리(DALL·E)의 활용 사례를 살펴본 결과 첫째, 달리(DALL·E)는 디자이너와 예술가에게 상상의 이미지를 시각화 시켜주는 도구로 창의적 영감의 원천으로 활용될 수 있다. 둘째, 이미지 생성 AI는 기업의 광고나 마케팅, 홍보에 적용하여 상업적인 도구로 활용이 가능하다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219382 \n",
      "\n",
      "제목: 유아 인공지능(AI) 관련 연구 동향 분석\n",
      "초록이: 본 연구는 유아 인공지능 관련 연구 동향을 살펴봄으로써 앞으로의 유아 인공지능 관련 연구가 나아가야 할 방향을 제시하고 관련 연구의 토대를 확고히 하기 위하여 시도되었다. 이를 위해 최근 7년간 실시되어온 유아 에 관한 국내 학술지 논문과 학위논문을 연도, 연구대상, 연구방법, 연구내용별로 구분하여 검토하고 분석하였으며 연구결과는 다음과 같다. 첫째, 국내 관련 연구는 연구가 처음 실시된 2017년을 시작으로 2023년까지 꾸준히 시행되었으며 2022년에 급격히 증가하는 경향을 보였다. 둘째, 연구대상은 교사를 대상으로 하는 연구가 가장 많이 나타났고, 문헌 및 연구물, 유아, 애플리케이션 및 콘텐츠를 대상으로 하는 연구가 순서대로 나타났다. 셋째, 연구방법으로는 양적연구가 가장 많았으며 문헌연구, 질적연구, 혼합연구가 순서대로 나타났다.\n",
      "링크: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219168 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time #time.sleep()쓰기 위함 \n",
    "from selenium import webdriver  #webdriver 쓰기 위함 \n",
    "from selenium.webdriver.chrome.options import Options  #이 코드라인이 없으면, 에러가 나온다. \n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 크롬 옵션 headless 모드로 실행\n",
    "options = Options()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--window-size=1080,1080')\n",
    "\n",
    "\n",
    "# 크롬 드라이버 경로 지정\n",
    "driver_path = 'chromedriver'\n",
    "\n",
    "# 크롬 드라이버 객체 생성\n",
    "browser = webdriver.Chrome(executable_path=driver_path, options=options)\n",
    "\n",
    "\n",
    "\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5'\n",
    "browser.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "data = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "#링크가져오기 \n",
    "\n",
    "detail_url_list = []\n",
    "for i in data:\n",
    "    detail_url = i.get_attribute('href')\n",
    "    detail_url_list.append(detail_url)\n",
    "\n",
    "#논문 제목 가져오기 \n",
    "\n",
    "title_list = []\n",
    "\n",
    "\n",
    "for i in data:\n",
    "    title = i.find_element(By.TAG_NAME,'h2').text\n",
    "    title_list.append(title)\n",
    "    \n",
    "#논문 컨텐츠 가져오기    \n",
    "    \n",
    "content_list = []\n",
    "\n",
    "for i in data:\n",
    "    try:\n",
    "        content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "    except:\n",
    "        # print(\"No text value for class='thesis__abstract'\")\n",
    "        content = ''\n",
    "    content_list.append(content)\n",
    "    \n",
    "    \n",
    "dbpia_list = []\n",
    "for i in data:\n",
    "    try:\n",
    "        title = i.find_element(By.TAG_NAME,'h2').text\n",
    "        content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "        detail_url = i.get_attribute('href')\n",
    "    except:\n",
    "        title = ''\n",
    "        content=''\n",
    "        detail_url=''\n",
    "    dbpia_list.append({'제목': title, '초록이': content, '링크': detail_url})\n",
    "    \n",
    "for item in dbpia_list:\n",
    "    print('제목:', item['제목'])\n",
    "    print('초록이:', item['초록이'])\n",
    "    print('링크:', item['링크'], '\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엑셀파일로 저장하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\enter\\miniconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\enter\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\enter\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\enter\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\enter\\miniconda3\\lib\\site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\enter\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dbpia_list = []\n",
    "for i in data:\n",
    "    try:\n",
    "        title = i.find_element(By.TAG_NAME,'h2').text\n",
    "        content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "        detail_url = i.get_attribute('href')\n",
    "    except:\n",
    "        title = ''\n",
    "        content=''\n",
    "        detail_url=''\n",
    "    dbpia_list.append({'제목': title, '초록이': content, '링크': detail_url})\n",
    "\n",
    "df = pd.DataFrame(dbpia_list)\n",
    "df.to_csv('./dbpia_data_index_true.csv', encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음페이지 넘어가는 크롤링 코드 구현 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지마다 크롤링 결과가 누적되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #time.sleep()쓰기 위함 \n",
    "from selenium import webdriver  #webdriver 쓰기 위함 \n",
    "from selenium.webdriver.chrome.options import Options  #이 코드라인이 없으면, 에러가 나온다. \n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 크롬 옵션 headless 모드로 실행\n",
    "options = Options()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--window-size=1080,1080')\n",
    "\n",
    "\n",
    "# 크롬 드라이버 경로 지정\n",
    "driver_path = 'chromedriver'\n",
    "\n",
    "# 크롬 드라이버 객체 생성\n",
    "browser = webdriver.Chrome(executable_path=driver_path, options=options)\n",
    "\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5'\n",
    "browser.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "for page_num in range(1, 11): \n",
    "    data = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "    dbpia_list = []\n",
    "    for i in data:\n",
    "        try:\n",
    "            title = i.find_element(By.TAG_NAME,'h2').text\n",
    "            content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "            detail_url = i.get_attribute('href')\n",
    "        except:\n",
    "            title = ''\n",
    "            content=''\n",
    "            detail_url=''\n",
    "        dbpia_list.append({'제목': title, '초록이': content, '링크': detail_url})\n",
    "\n",
    "    for item in dbpia_list:\n",
    "        print('제목:', item['제목'])\n",
    "        print('초록이:', item['초록이'])\n",
    "        print('링크:', item['링크'], '\\n')\n",
    "    \n",
    "    if page_num != 10:\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        next_page = browser.find_element(By.XPATH, f\"//a[@onclick='setPageNum({page_num + 1})']\")\n",
    "        next_page.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "len(dbpia_list)  #20개의 길이가 출력된다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지마다 크롤링 결과가 누적된다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나의 코드 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강사님 수업 04.20  코드 \n",
    "\n",
    "-   페이지 이동시, XPATH로 \n",
    "\n",
    "- 1. DB PIA 사이트로 간다.\n",
    "- 2. 1페이지에 있는 논문 링크들을 다 가져온다. \n",
    "- 3. 페이지에 있는 링크값들을 다 가져오고, \n",
    "- 4. 5초를 쉰다. \n",
    "- 5. 2페이지로 간다. \n",
    "- 6. 2페이지에 있는 논문 링크들을 다 가져온다.\n",
    "- 7. 3페이지로 간다.\n",
    "- 8. 5초를 쉰다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libary import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import time # 시간 딜레이시 사용\n",
    "import pandas as pd # 엑셀 저장시 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이트 이동\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230851', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230843', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230845', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230844', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288340', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231160', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231378', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288024', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231192', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230847', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11337935', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230365', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11342633', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231818', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11343329', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11225163', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11229021', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228571', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11228572', 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219382']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 논문 링크만 쭉 가져오는 코드\n",
    "# link = browser.find_element(By.CLASS_NAME, 'thesis__link').get_attribute('href')\n",
    "datas = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "detail_url_list = []\n",
    "for i in datas:\n",
    "    detail_url = i.get_attribute('href')\n",
    "    detail_url_list.append(detail_url)\n",
    "\n",
    "print(detail_url_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 페이지 이동하는 강사님 수업 내용 23.04.20\n",
    "\n",
    "해당 페이지의 링크 값들을 다 가져와서 link_list에 저장을 가져온다. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 이동 시 주의 사항 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (140041824.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    매번 5초간 대기하는 경우 IP 차단당할 수 있다.\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "browser.implicitly_wait(time_to_wait=5) # 암묵적 대기, 해당 시간만큼 대기\n",
    "\n",
    "time.sleep(5) # 무작정 대기\n",
    "\n",
    "매번 5초간 대기하는 경우 IP 차단당할 수 있다.\n",
    "time.sleep(random.randint(1,10)) 이것을 사용하면 된다.\n",
    "\n",
    "https://www.selenium.dev/documentation/webdriver/waits/ \n",
    "\n",
    "공식홈페이지를 읽어보자!\n",
    "\n",
    "*두 개를 적절하게 잘 섞어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.sleep(5) # 무조건 5초를 기다려 => 반복적인 행위를 피하고 싶을 때 사용\n",
    "browser.implicitly_wait(5) # 로딩이 5초안에 완료되면 다음 코드를 실행해 => 네이버날씨 넷플릭스 TOP10을 1시간마다 크롤링 하고 싶어 할때는 이것으로 최적화를 하는 것이다. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 이동 방법1. 버튼을 클릭하는 코드 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# //*[@id=\"pageList\"]/a[1]\n",
    "# //*[@id=\"pageList\"]/a[2]\n",
    "# //*[@id=\"pageList\"]/a[3]\n",
    "# 다음페이지로 넘어가는 버튼의 XPATH에 반복되는 코드들이 보인다. 규칙을 찾는다.\n",
    "\n",
    "\n",
    "page = '//*[@id=\"pageList\"]/a[{}]'\n",
    "\n",
    "for i in range(1,4):\n",
    "    final_page = page.format(i)\n",
    "    print(final_page)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 페이지 이동 방법2. 페이지 URL의 규칙을 찾는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=검색어&start=0\n",
      "https://www.google.com/search?q=검색어&start=10\n",
      "https://www.google.com/search?q=검색어&start=20\n",
      "https://www.google.com/search?q=검색어&start=30\n",
      "https://www.google.com/search?q=검색어&start=40\n",
      "https://www.google.com/search?q=검색어&start=50\n",
      "https://www.google.com/search?q=검색어&start=60\n",
      "https://www.google.com/search?q=검색어&start=70\n",
      "https://www.google.com/search?q=검색어&start=80\n",
      "https://www.google.com/search?q=검색어&start=90\n"
     ]
    }
   ],
   "source": [
    "#각 페이지가 어떤 논리로 구성되어 있는지 보는 코드 \n",
    "\n",
    "\n",
    "\n",
    "# https://www.google.com/search?q=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&tbm=nws&ei=SoVAZOndLMmx2roPyPOX8Ag&start=0 - 1페이지\n",
    "# https://www.google.com/search?q=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&tbm=nws&ei=SoVAZOndLMmx2roPyPOX8Ag&start=10 - 2페이지\n",
    "# https://www.google.com/search?q=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&tbm=nws&ei=U4VAZPbYKobf2roPmq-ayA4&start=20 - 3페이지\n",
    "# https://www.google.com/search?q=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5&tbm=nws&ei=eYVAZKjqNc3M2roP0NKSuAM&start=90 - 10페이지\n",
    "# tbm => tab menu - nws(news) # GET data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 네이버카페, \n",
    "# 네이버뉴스, 크롤링도 이 규칙을 벗어나지 않는다. \n",
    "\n",
    "\n",
    "\n",
    "url = \"https://www.google.com/search?q=검색어&start={}\" #위 링크를 보고, 아 애네들은 이게 기본 뼈대구나. 생각할 수 있다. \n",
    "#우리는 규칙을 찾았으니, 이제 어떻게 하면될까?\n",
    "\n",
    "for i in range(0,100, 10):  #0부터 100까지 가는데, 10씩 커졌으면 좋겠는데, \n",
    "    final_url = url.format(i)\n",
    "    print(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'page_xpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# 페이지 이동 하는 코드 \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# //*[@id=\"pageList\"]/a[3]\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# 다음페이지로 넘어가는 버튼에 \u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m):\n\u001b[1;32m---> 20\u001b[0m     next_page_xpath \u001b[39m=\u001b[39m page_xpath\u001b[39m.\u001b[39mformat(i)\n\u001b[0;32m     21\u001b[0m     browser\u001b[39m.\u001b[39mfind_element(By\u001b[39m.\u001b[39mXPATH, next_page_xpath)\u001b[39m.\u001b[39mclick()\n\u001b[0;32m     22\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)  \u001b[39m#페이지이동후 쉬자.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'page_xpath' is not defined"
     ]
    }
   ],
   "source": [
    "# 페이지 이동 하는 코드 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# //*[@id=\"pageList\"]/a[1]\n",
    "# //*[@id=\"pageList\"]/a[2]\n",
    "# //*[@id=\"pageList\"]/a[3]\n",
    "# 다음페이지로 넘어가는 버튼의 XPATH에 반복되는 코드들이 보인다. 규칙을 찾는다.\n",
    "\n",
    "\n",
    "page_xpath = '//*[@id=\"pageList\"]/a[{}]'  #페이지 규칙을 찾아서 만든 page_xpath\n",
    "\n",
    "\n",
    "for i in range(1,3):\n",
    "    next_page_xpath = page_xpath.format(i)\n",
    "    browser.find_element(By.XPATH, next_page_xpath).click()\n",
    "    time.sleep(5)  #페이지이동후 쉬자.\n",
    "\n",
    "    # 해당 페이지의 링크 값들을 다 가져와서 link_list에 저장을 한다.\n",
    "    links = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "\n",
    "#\n",
    "    for j in links:\n",
    "        # print(j.get_attribute('href'))\n",
    "        j.get_attribute('href')\n",
    "\n",
    "\n",
    "# j 에 도대체 뭐가 들어가 있을까? \n",
    "\n",
    "# <a href=\"/journal/articleDetail?nodeId=NODE11230851\" target=\"_blank\" class=\"thesis__link title\" data-statistics-code=\"Z104\">\n",
    "#                         <h2 class=\"thesis__tit\"><b>인공지능</b> 융합교육을 위한 초중등학교 연계형 <b>인공지능</b> 교육 내용체계 개발</h2>\n",
    "#                         <span class=\"thesis__abstract\">본 연구의 목적은 체계적인 <em>인공지능</em> 융합교육을 지원하기 위한 초중등학교 연계형 <em>인공지능</em> 교육 내용체계를 개발하는 것이다.  이를 위해, 국내·외 <em>인공지능</em> 교육 관련 내용 체계 동향을 분석하여 초중등 학교급별 교육영역 및 내용요소를 추출하였다.  <em>인공지능</em> 내용체계 초안에 대해 11명의 전문가에게 2차에 걸친 델파이 및 FGI를 통해 수정 보완하여 타당도를 검증하였다.  연구 결과, <em>인공지능</em> 교육 내용체계는 초등학교 1~4학년과 5~6학년, 중학교, 고등학교의 4단계로 제시되었다.  또한, 이 내용체계는 'AI 이해', 'AI 윤리', 'AI 활용', 'AI 융합'의 4개 대영역과 총 9개의 하위영역으로 구성되었으며, 총 95개의 내용요소를 제시함으로써 모든 영역에서 학교급별로 연계될 수 있도록 개발하였다.</span>\n",
    "#                         <section class=\"thesis__keyword\" m-hidden=\"\">\n",
    "#                             <i><b>인공지능</b></i><i><b>인공지능</b> 교육</i><i><b>인공지능</b> 융합 교육</i>\n",
    "#                         </section>\n",
    "#                     </a>\n",
    "\n",
    "j 안에는 이렇게 많은 데이터가 들어가 있다.\n",
    "근데 내가 원하는 것은 href 속성이다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time #time.sleep()쓰기 위함 \n",
    "from selenium import webdriver  #webdriver 쓰기 위함 \n",
    "from selenium.webdriver.chrome.options import Options  #이 코드라인이 없으면, 에러가 나온다. \n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 크롬 옵션 headless 모드로 실행\n",
    "options = Options()\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--window-size=1080,1080')\n",
    "\n",
    "\n",
    "# 크롬 드라이버 경로 지정\n",
    "driver_path = 'chromedriver'\n",
    "\n",
    "# 크롬 드라이버 객체 생성\n",
    "browser = webdriver.Chrome(executable_path=driver_path, options=options)\n",
    "\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5'\n",
    "browser.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpia_list = []\n",
    "\n",
    "for page_num in range(1, 11): \n",
    "    data = browser.find_elements(By.CLASS_NAME, 'thesis__link')\n",
    "    \n",
    "    for i in data:\n",
    "        try:\n",
    "            title = i.find_element(By.TAG_NAME,'h2').text\n",
    "            content = i.find_element(By.CLASS_NAME,'thesis__abstract').text\n",
    "            detail_url = i.get_attribute('href')\n",
    "        except:\n",
    "            title = ''\n",
    "            content=''\n",
    "            detail_url=''\n",
    "        dbpia_list.append({'제목': title, '초록이': content, '링크': detail_url})\n",
    "\n",
    "    if page_num != 10:\n",
    "        next_page = browser.find_element(By.XPATH, f\"//a[@onclick='setPageNum({page_num + 1})']\")\n",
    "        next_page.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "print(len(dbpia_list))\n",
    "\n",
    "for item in dbpia_list:\n",
    "    print('제목:', item['제목'])\n",
    "    print('초록이:', item['초록이'])\n",
    "    print('링크:', item['링크'], '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
